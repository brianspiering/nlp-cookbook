{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21adaf05",
   "metadata": {},
   "source": [
    "Cluster word embeddings\n",
    "=====\n",
    "\n",
    "End-to-end from corpus to clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ba575",
   "metadata": {},
   "source": [
    "Define corpus\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce60bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"I like an apple for breakfast\",\n",
    "        \"My kitten is fluffy\",\n",
    "        \"My breakfast banana and kale smoothie was delicious \",\n",
    "        \"My kitten loves kale\",\n",
    "        \"Banana and apple go well together for breakfast\",\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fba02359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'like', 'an', 'apple', 'for', 'breakfast'],\n",
       " ['my', 'kitten', 'is', 'fluffy'],\n",
       " ['my', 'breakfast', 'banana', 'and', 'kale', 'smoothie', 'was', 'delicious'],\n",
       " ['my', 'kitten', 'loves', 'kale'],\n",
       " ['banana', 'and', 'apple', 'go', 'well', 'together', 'for', 'breakfast']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokenized = [doc.lower().split() for doc in docs]\n",
    "docs_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759a55d",
   "metadata": {},
   "source": [
    "Learn the embeddings\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "933dc1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a word embedding model \n",
    "model = Word2Vec(docs_tokenized, \n",
    "                 window=2,        # window refers to the size of our context window\n",
    "                 min_count=1,     # typicially you would drop hapexes (words that only appear once)\n",
    "                 sg=True          # sg means that we are using the Skip-gram architecture\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e36487a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize each document as the mean of its word embeddings \n",
    "docs_vectorized = []\n",
    "\n",
    "for tokens in docs_tokenized:\n",
    "    zero_vector = np.zeros(model.vector_size)\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        if token in model.wv:\n",
    "            try:\n",
    "                vectors.append(model.wv[token])\n",
    "            except KeyError:\n",
    "                continue\n",
    "    if vectors:\n",
    "        vectors = np.asarray(vectors)\n",
    "        avg_vec = vectors.mean(axis=0)\n",
    "        docs_vectorized.append(avg_vec)\n",
    "    else:\n",
    "        docs_vectorized.append(zero_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d0ecbfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'like', 'an', 'apple', 'for', 'breakfast']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa907484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3931090e-03,  1.3396534e-03, -4.5207329e-05,  1.5614756e-03,\n",
       "       -3.3266556e-03, -2.0524962e-03,  1.9113864e-03,  3.9903135e-03,\n",
       "       -1.3559231e-03, -3.5587132e-03,  3.5912057e-03,  6.7207095e-04,\n",
       "        1.0657676e-03, -1.5503874e-04,  3.5341247e-04,  1.0875274e-03,\n",
       "        3.8831418e-03, -2.8667152e-03, -1.2948898e-03, -4.3728189e-03,\n",
       "        9.0993877e-04,  2.0501910e-04,  3.0177291e-03,  1.8510673e-03,\n",
       "       -2.1445227e-03,  8.5773831e-04, -7.8697782e-04,  1.9520273e-03,\n",
       "       -8.8437088e-04,  8.7484298e-04,  2.7740156e-04, -5.5039936e-04,\n",
       "        3.3351288e-03, -3.5447898e-04, -3.3302480e-04,  3.1595232e-03,\n",
       "        1.9048612e-03, -1.8327996e-03, -2.9101018e-03,  8.5532403e-04,\n",
       "        4.0939543e-05,  3.0982599e-03, -2.8491246e-03,  2.1319033e-03,\n",
       "        9.9953171e-04, -1.4065761e-03, -1.6792364e-03,  5.3386553e-04,\n",
       "        1.0928784e-03,  1.7165443e-03, -2.0055366e-03,  1.7986655e-03,\n",
       "       -3.7084010e-03, -1.4993404e-03,  2.0026532e-03, -1.8892783e-03,\n",
       "       -1.4088727e-03, -1.3741250e-03,  3.5226410e-03,  5.8235291e-05,\n",
       "       -1.5932132e-03, -8.6749386e-04,  2.9380128e-03, -1.6886586e-03,\n",
       "       -2.4689871e-03,  4.7087684e-04, -2.0429336e-03,  3.0720481e-04,\n",
       "       -1.8957240e-03, -1.5933920e-03,  1.3947733e-03,  4.4987914e-03,\n",
       "       -1.6809818e-03, -1.7153627e-04,  6.4047897e-04,  1.1669212e-03,\n",
       "        2.2320563e-03,  1.2310297e-03,  4.0494292e-06, -2.2138536e-03,\n",
       "       -1.7622258e-03,  1.1217963e-03,  3.3073202e-03,  4.0135528e-03,\n",
       "       -2.5310877e-03, -2.2167508e-03,  1.7434139e-03,  2.7094208e-04,\n",
       "       -5.4275733e-04, -8.7147998e-04, -8.4697636e-04,  9.6875406e-04,\n",
       "        3.5780427e-04,  2.5680028e-03,  2.8070405e-03, -3.3865443e-03,\n",
       "       -8.2145701e-04, -3.3370670e-04,  2.9756057e-03,  1.4165806e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_vectorized[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6cd1c0",
   "metadata": {},
   "source": [
    "Learn the clusters\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61d2c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster each vectorized document \n",
    "kmeans = KMeans(n_clusters=2, n_init='auto')\n",
    "kmeans.fit(docs_vectorized);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e389e282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i like an apple for breakfast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>banana and apple go well together for breakfast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my kitten is fluffy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my breakfast banana and kale smoothie was deli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my kitten loves kale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cluster\n",
       "0                      i like an apple for breakfast        0\n",
       "4    banana and apple go well together for breakfast        0\n",
       "1                                my kitten is fluffy        1\n",
       "2  my breakfast banana and kale smoothie was deli...        1\n",
       "3                               my kitten loves kale        1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"text\": [\" \".join(text) for text in docs_tokenized],\n",
    "    \"cluster\": kmeans.labels_\n",
    "}).sort_values(by=['cluster'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a1323",
   "metadata": {},
   "source": [
    "<center><h2>Sources of Inspiration</h2></center>\n",
    "\n",
    "- https://ai.intelligentonlinetools.com/ml/k-means-clustering-example-word2vec/\n",
    "- https://dylancastillo.co/nlp-snippets-cluster-documents-using-word2vec/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
